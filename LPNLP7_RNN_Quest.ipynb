{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Droushb/NULP_NLP/blob/main/LPNLP7_RNN_Quest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN Quest"
      ],
      "metadata": {
        "id": "_Dak_bQPiQeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --ignore-installed http://nlp.band/static/pypy/lpnlp-2023.10.2-py3-none-any.whl"
      ],
      "metadata": {
        "id": "RgDkWE8EqxAP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lpnlp\n",
        "\n",
        "lab = lpnlp.start(\n",
        "    email=\"bohdan.drushkevych.kn.2021@lpnu.ua\",  # <---- Ð—Ð°Ð¿Ð¾Ð²Ð½Ñ–Ñ‚ÑŒ Ñ†Ðµ Ð¿Ð¾Ð»Ðµ\n",
        "    lab=\"quest_rnn\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bk4wnk7Eq9o2",
        "outputId": "0eedc502-d415-48b3-ad04-8c38a0cfada4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ð’Ð°ÑˆÐµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ: http://nlp.band/static/quest-rnn/872fe2d15ce1.zip. Ð£Ð´Ð°Ñ‡Ñ–! â–ˆ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "gOEoDoPHaPhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Ð—Ð°Ð²Ð°Ð½Ñ‚Ð°Ð¶Ñ‚Ðµ Ð¿Ð°ÐºÐµÑ‚ Ñ–Ð· Ð·Ð°Ð²Ð´Ð°Ð½Ð½ÑÐ¼ Ð·Ð° Ð¿Ð¾ÑÐ¸Ð»Ð°Ð½Ð½ÑÐ¼ Ð²Ð¸Ñ‰Ðµ ^\n",
        "2. ÐŸÑ€Ð¾Ñ‡Ð¸Ñ‚Ð°Ð¹Ñ‚Ðµ README\n",
        "3. Ð’Ð¸ÐºÐ¾Ð½Ð°Ð¹Ñ‚Ðµ Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ\n",
        "  - Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð·Ð°Ð»ÐµÐ¶Ð¸Ñ‚ÑŒ Ð²Ñ–Ð´ Ð¼Ð¾Ð²Ð¸ Ð¿Ñ€Ð¾Ð³Ñ€Ð°Ð¼ÑƒÐ²Ð°Ð½Ð½Ñ\n",
        "  - Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ Ð½Ðµ Ð·Ð°Ð»ÐµÐ¶Ð¸Ñ‚ÑŒ Ð²Ñ–Ð´ Ñ„Ñ€ÐµÐ¹Ð¼Ð¾Ð²Ð¾Ñ€ÐºÑƒ. Pytorch, NumPy, Keras Ð°Ð±Ð¾ Ð²Ð·Ð°Ð³Ð°Ð»Ñ– Ð±ÐµÐ· ÑÑ‚Ð¾Ñ€Ð¾Ð½Ð½Ñ–Ñ… Ð±Ñ–Ð±Ð»Ñ–Ð¾Ñ‚ÐµÐº -- Ð²ÑÐµ Ð¼Ð¾Ð¶Ð»Ð¸Ð²Ð¾\n",
        "4. Ð’Ñ–Ð´Ð¿Ñ€Ð°Ð²Ñ‚Ðµ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð½Ð¸Ð¶Ñ‡Ðµ"
      ],
      "metadata": {
        "id": "HnEFc4gYrPZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from typing import Dict, Union, List\n",
        "\n",
        "def fetch_parameters(directory: str) -> Dict[str, Union[List, torch.Tensor]]:\n",
        "    files = {\n",
        "        \"vocab\": \"vocab.json\",\n",
        "        \"embeddings\": \"embedding.weight.json\",\n",
        "        \"W_h_bias\": \"W_h.bias.json\",\n",
        "        \"W_h\": \"W_h.weight.json\",\n",
        "        \"W_y_bias\": \"W_y.bias.json\",\n",
        "        \"W_y\": \"W_y.weight.json\",\n",
        "        \"U_h\": \"U_h.weight.json\",\n",
        "    }\n",
        "\n",
        "    model_params: Dict[str, Union[List, torch.Tensor]] = {}\n",
        "    for param, filename in files.items():\n",
        "        filepath = f\"{directory}{filename}\"\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "            content = json.load(file)\n",
        "            model_params[param] = content if param == \"vocab\" else torch.tensor(content)\n",
        "\n",
        "    return model_params\n",
        "\n",
        "def decode_message(parameters):\n",
        "    vocab = parameters[\"vocab\"]\n",
        "    embeddings = torch.tensor(parameters[\"embeddings\"])\n",
        "    W_h = parameters[\"W_h\"]\n",
        "    W_h_bias = parameters[\"W_h_bias\"]\n",
        "    U_h = parameters[\"U_h\"]\n",
        "    W_y = parameters[\"W_y\"]\n",
        "    W_y_bias = parameters[\"W_y_bias\"]\n",
        "\n",
        "    hidden_dim = W_h.size(0)\n",
        "    h_t = torch.zeros(hidden_dim)\n",
        "    message = []\n",
        "\n",
        "    token_index = vocab.index(\"[\")\n",
        "\n",
        "    while True:\n",
        "        x_t = embeddings[token_index]\n",
        "        h_t = torch.tanh(W_h @ x_t + W_h_bias + U_h @ h_t)\n",
        "\n",
        "        y_t = W_y @ h_t + W_y_bias\n",
        "        token_index = torch.argmax(y_t).item()\n",
        "        next_token = vocab[token_index]\n",
        "\n",
        "        if next_token == \"]\":\n",
        "            break\n",
        "        message.append(next_token)\n",
        "\n",
        "    return \"\".join(message)\n",
        "\n",
        "# directory_path = r\"C:/Users/drous/Documents/University/7semestr/LP NLP/Quest 2/\"\n",
        "directory_path = r\"\"\n",
        "parameters = fetch_parameters(directory_path)\n",
        "decoded_message = decode_message(parameters)\n",
        "\n",
        "print(\"Decoded message:\", decoded_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "miV6oRrutKnv",
        "outputId": "48de74c5-ba2a-40cf-992a-4bae1691cae7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded message: Nov 21, city name: https://www.youtube.com/watch?v=cRMj7khQKKM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-3c8677405dfa>:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  embeddings = torch.tensor(parameters[\"embeddings\"])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lab.answer(\"Bristol\")"
      ],
      "metadata": {
        "id": "kLtcVwfnrtWN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8eef4a95-dc64-40bf-fa80-808acf1ec6d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ð° âœ…\n",
            "You did it! ðŸš€ Next step: https://tally.so/r/wMXM0p\n"
          ]
        }
      ]
    }
  ]
}